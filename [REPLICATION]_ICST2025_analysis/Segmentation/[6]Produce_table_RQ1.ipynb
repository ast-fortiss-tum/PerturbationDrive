{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table with inline barplots saved as summary_table_with_charts.tex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory containing CSV files\n",
    "csv_folder = \"content/evaluation/model_pert\"\n",
    "\n",
    "# Directory for barplot images (not needed, keeping it in case)\n",
    "output_dir = 'barplot_images_2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(csv_folder, \"*.csv\"))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through all CSV files\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Extract the perturbation name and intensity using regex\n",
    "    df[['Perturbation', 'Intensity']] = df['Weather Type'].str.extract(r\"b'0020_(.+)_(\\d)'\")\n",
    "\n",
    "    # Drop the original 'Weather Type' column\n",
    "    df = df.drop('Weather Type', axis=1)\n",
    "    \n",
    "    # Convert 'Intensity' to an integer\n",
    "    df['Intensity'] = df['Intensity'].astype(int)\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_remove = ['Average MAE', 'Overall Specificity', 'Average Pixel Accuracy', 'Overall Accuracy', \n",
    "                     'Overall Precision', 'Overall Recall', 'Overall Dice Coefficient']\n",
    "combined_df = combined_df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Sort values by Perturbation and Intensity\n",
    "combined_df = combined_df.sort_values(by=['Perturbation', 'Intensity'])\n",
    "\n",
    "# Calculate the mean for each perturbation group (without variance)\n",
    "grouped_df = combined_df.groupby('Perturbation').agg(['mean']).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex in the column names\n",
    "grouped_df.columns = ['Perturbation'] + ['_'.join(col).strip() for col in grouped_df.columns if col[0] != 'Perturbation']\n",
    "\n",
    "# Function to normalize values between 0 and 1 for LaTeX barplots\n",
    "def normalize_values_for_chart(values):\n",
    "    min_value = np.min(values)\n",
    "    max_value = np.max(values)\n",
    "    \n",
    "    if min_value == max_value:\n",
    "        return [0.5 for _ in values]\n",
    "    \n",
    "    return [(val - min_value) / (max_value - min_value) for val in values]\n",
    "\n",
    "# Function to generate LaTeX \\Chart{} command for each perturbation and metric\n",
    "def generate_chart_latex(perturbation, metric, df):\n",
    "    \"\"\"Generate the LaTeX \\Chart{} command for the given perturbation and metric across all intensities.\"\"\"\n",
    "    intensities = df[df['Perturbation'] == perturbation]['Intensity']\n",
    "    metric_values = df[df['Perturbation'] == perturbation][metric].values\n",
    "    \n",
    "    # Normalize the metric values for LaTeX barplot\n",
    "    normalized_values = normalize_values_for_chart(metric_values)\n",
    "    \n",
    "    # Convert normalized values to LaTeX \\Chart{} command with 5 bars\n",
    "    chart_latex = f\"\\\\Chart{{{normalized_values[0]:.2f}}}{{{normalized_values[1]:.2f}}}{{{normalized_values[2]:.2f}}}{{{normalized_values[3]:.2f}}}{{{normalized_values[4]:.2f}}}\"\n",
    "    \n",
    "    return chart_latex\n",
    "\n",
    "# Add LaTeX \\Chart{} commands for each perturbation and metric\n",
    "def add_chart_commands(df):\n",
    "    for metric in combined_df.columns:\n",
    "        if metric not in ['Perturbation', 'Intensity']:\n",
    "            df[f'{metric}_Chart'] = df['Perturbation'].apply(lambda p: generate_chart_latex(p, metric, combined_df))\n",
    "    return df\n",
    "\n",
    "# Generate inline barplots for the metrics and store LaTeX commands in the DataFrame\n",
    "grouped_df_with_charts = add_chart_commands(grouped_df)\n",
    "\n",
    "# Custom LaTeX table generation with mean and inline barplots (no variance)\n",
    "def dataframe_to_latex_with_charts(df):\n",
    "    latex_lines = []  # Initialize the latex_lines list to collect LaTeX code\n",
    "    num_metrics = (len(df.columns) - 1) // 2  # Exclude the Perturbation column (we now have mean and chart per metric)\n",
    "    \n",
    "    # Create the top-level header (one column for each metric, split into mean and chart)\n",
    "    latex_lines.append(\"\\\\begin{tabular}{l%s}\" % (\"rr\" * num_metrics))\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    \n",
    "    # Add multi-column headers for each metric\n",
    "    metric_names = ['Average MSE', 'Overall F1 Score', 'Overall IoU']  # Assuming these metrics from your table\n",
    "    header_row_1 = ['Perturbation'] + [f\"\\\\multicolumn{{2}}{{c}}{{{metric}}}\" for metric in metric_names]\n",
    "    latex_lines.append(\" & \".join(header_row_1) + \" \\\\\\\\\")\n",
    "    \n",
    "    # Add the sub-headers (mean and barplot)\n",
    "    header_row_2 = [''] + ['Mean', 'Trend'] * len(metric_names)\n",
    "    latex_lines.append(\" & \".join(header_row_2) + \" \\\\\\\\\")\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    \n",
    "    # Add data rows\n",
    "    for _, row in df.iterrows():\n",
    "        row_str = [row['Perturbation']]\n",
    "        for metric in metric_names:\n",
    "            row_str.append(f\"{row[f'{metric}_mean']:.2f}\")\n",
    "            row_str.append(f\"{row[f'{metric}_Chart']}\")\n",
    "        latex_lines.append(\" & \".join(row_str) + \" \\\\\\\\\")\n",
    "    \n",
    "    # Final closing line and end of table\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\end{tabular}\")\n",
    "    \n",
    "    return \"\\n\".join(latex_lines)\n",
    "\n",
    "# Generate LaTeX table with inline barplots\n",
    "latex_table = dataframe_to_latex_with_charts(grouped_df_with_charts)\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "with open(\"summary_table_with_charts.tex\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"LaTeX table with inline barplots saved as summary_table_with_charts.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table with IoU metrics saved as iou_summary_table.tex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Directory containing CSV files\n",
    "csv_folder = \"content/evaluation/model_pert\"\n",
    "\n",
    "# Directory for barplot images (not needed, keeping it in case)\n",
    "output_dir = 'barplot_images_2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(csv_folder, \"*.csv\"))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through all CSV files\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Extract the perturbation name and intensity using regex\n",
    "    df[['Perturbation', 'Intensity']] = df['Weather Type'].str.extract(r\"b'0020_(.+)_(\\d)'\")\n",
    "\n",
    "    # Drop the original 'Weather Type' column\n",
    "    df = df.drop('Weather Type', axis=1)\n",
    "    \n",
    "    # Convert 'Intensity' to an integer\n",
    "    df['Intensity'] = df['Intensity'].astype(int)\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_remove = ['Average MAE', 'Overall Specificity', 'Average Pixel Accuracy', 'Overall Accuracy', \n",
    "                     'Overall Precision', 'Overall Recall', 'Overall Dice Coefficient']\n",
    "combined_df = combined_df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Sort values by Perturbation and Intensity\n",
    "combined_df = combined_df.sort_values(by=['Perturbation', 'Intensity'])\n",
    "\n",
    "# Group by Perturbation and calculate mean, max, min, and variance for 'Overall IoU'\n",
    "grouped_df = combined_df.groupby('Perturbation').agg({\n",
    "    'Overall IoU': ['mean', 'max', 'min', 'var']\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the columns to have a single level instead of a MultiIndex\n",
    "grouped_df.columns = ['Perturbation', 'IoU_Average', 'IoU_Max', 'IoU_Min', 'IoU_Variance']\n",
    "\n",
    "# Custom LaTeX table generation for Overall IoU metrics\n",
    "def dataframe_to_latex_with_iou(df):\n",
    "    latex_lines = []  # Initialize the latex_lines list to collect LaTeX code\n",
    "    \n",
    "    # Create the top-level header (Overall IoU with four subcolumns)\n",
    "    latex_lines.append(\"\\\\begin{tabular}{lrrrr}\")\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    \n",
    "    # Add multi-column headers for Overall IoU\n",
    "    header_row_1 = ['Perturbation', '\\\\multicolumn{4}{c}{Overall IoU}']\n",
    "    latex_lines.append(\" & \".join(header_row_1) + \" \\\\\\\\\")\n",
    "    \n",
    "    # Add the sub-headers (Average, Max, Min, Variance)\n",
    "    header_row_2 = ['', 'Average', 'Max', 'Min', 'Variance']\n",
    "    latex_lines.append(\" & \".join(header_row_2) + \" \\\\\\\\\")\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    \n",
    "    # Add data rows\n",
    "    for _, row in df.iterrows():\n",
    "        row_str = [\n",
    "            row['Perturbation'],\n",
    "            f\"{row['IoU_Average']:.2f}\",\n",
    "            f\"{row['IoU_Max']:.2f}\",\n",
    "            f\"{row['IoU_Min']:.2f}\",\n",
    "            f\"{row['IoU_Variance']:.4f}\"  # Variance typically requires more decimal precision\n",
    "        ]\n",
    "        latex_lines.append(\" & \".join(row_str) + \" \\\\\\\\\")\n",
    "    \n",
    "    # Final closing line and end of table\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\end{tabular}\")\n",
    "    \n",
    "    return \"\\n\".join(latex_lines)\n",
    "\n",
    "# Generate LaTeX table for IoU metrics\n",
    "latex_table = dataframe_to_latex_with_iou(grouped_df)\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "with open(\"iou_summary_table.tex\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"LaTeX table with IoU metrics saved as iou_summary_table.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv4",
   "language": "python",
   "name": "tfenv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
